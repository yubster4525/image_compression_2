# StyleGAN3-HVAE Image Compression

A neural image compression system based on StyleGAN3 and Hierarchical Variational Autoencoders (HVAE). This project combines the generative power of StyleGAN3 with a custom HVAE encoder to enable high-quality image compression with controllable bitrates.

![StyleGAN3-HVAE Compression](https://raw.githubusercontent.com/NVlabs/stylegan3/main/docs/stylegan3-teaser-1920x1006.png)
*Image source: StyleGAN3 repository*

## Overview

Traditional image compression methods like JPEG and PNG are based on hand-designed algorithms with fixed assumptions about image structure. Neural compression leverages learned image priors to achieve higher compression ratios with better perceptual quality.

This project uses:
- **StyleGAN3**: A state-of-the-art alias-free generative model as the decoder/generator
- **HVAE**: A hierarchical variational autoencoder as the encoder that maps images to StyleGAN3's latent space
- **Hierarchical Encoding**: Features are extracted at multiple scales to preserve different levels of detail

## Features

- üöÄ **Neural Image Compression**: Leverages StyleGAN3's strong image priors for high-quality compression
- üß† **Hierarchical Encoders**: Captures features at different scales for better reconstruction
- üìä **Variable Bitrate**: Adjustable compression rate via latent quantization
- üñºÔ∏è **Domain-Specific Compression**: Can be trained on specific domains for optimized results
- üîÑ **MPS/CUDA Support**: Hardware acceleration on Mac (MPS) and NVIDIA GPUs (CUDA)
- üìù **Detailed Documentation**: Comprehensive guide on how StyleGAN3 and HVAE work together

## Installation

### Prerequisites

- Python 3.8+
- PyTorch 1.9+
- CUDA 11.1+ (for NVIDIA GPU support) or macOS with Apple Silicon (for MPS support)

### Setup

1. Clone this repository:
```bash
git clone https://github.com/yubster4525/image_compression_2.git
cd image_compression_2
```

2. Clone StyleGAN3 repository:
```bash
git clone https://github.com/NVlabs/stylegan3.git
```

3. Install dependencies:
```bash
pip install torch torchvision lpips pillow numpy tqdm
```

4. Download a pre-trained StyleGAN3 model:
```bash
mkdir -p models
# Download StyleGAN3-T FFHQ model
curl -L -o models/stylegan3-t-ffhq-1024x1024.pkl https://api.ngc.nvidia.com/v2/models/nvidia/research/stylegan3/versions/1/files/stylegan3-t-ffhq-1024x1024.pkl
```

## Usage

### Training the HVAE Encoder

Train the HVAE encoder on synthetic data generated by StyleGAN3:

```bash
python stylegan3_hvae_full.py \
  --generator models/stylegan3-t-ffhq-1024x1024.pkl \
  --output ./hvae_output \
  --resolution 256 \
  --batch_size 2 \
  --epochs 100 \
  --kl_weight 0.01 \
  --perceptual_weight 0.8
```

For training on MacOS with MPS acceleration, use:

```bash
python stylegan3_mps_train.py
```

### Compressing Images

After training, you can compress images using the trained encoder:

```python
import torch
from PIL import Image
from torchvision import transforms
import pickle
import numpy as np

from stylegan3_hvae_full import HVAE_VGG_Encoder, StyleGAN3Compressor

# Load StyleGAN3 generator
with open('models/stylegan3-t-ffhq-1024x1024.pkl', 'rb') as f:
    G = pickle.load(f)['G_ema'].cuda()

# Load trained encoder
checkpoint = torch.load('hvae_output/hvae_encoder_final.pt')
encoder = HVAE_VGG_Encoder(
    img_resolution=checkpoint['config']['max_resolution'],
    img_channels=checkpoint['config']['img_channels'],
    w_dim=checkpoint['config']['w_dim'],
    num_ws=checkpoint['config']['num_ws'],
    block_split=checkpoint['config']['block_split'],
)
encoder.load_state_dict(checkpoint['encoder_state_dict'])
encoder.cuda()

# Create compressor
compressor = StyleGAN3Compressor(encoder, G)

# Load and preprocess image
img = Image.open('input.jpg').convert('RGB')
transform = transforms.Compose([
    transforms.Resize((256, 256)),
    transforms.ToTensor(),
    transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])
])
img_tensor = transform(img).unsqueeze(0).cuda()

# Compress image (8-bit quantization)
compressor.save_compressed(img_tensor, 'compressed.npz', quantization_bits=8)

# Decompress image
reconstructed, compression_ratio = compressor.load_compressed('compressed.npz')
```

## Project Structure

- `stylegan3_hvae_guide.md`: Comprehensive guide to StyleGAN3+HVAE integration
- `vgg_hvae_encoder.py`: VGG-style HVAE encoder implementation
- `hvae_training.py`: Complete training pipeline
- `stylegan3_mps_train.py`: Version optimized for MPS (Metal Performance Shaders)
- `stylegan3_hvae_full.py`: Full-featured implementation with advanced compression
- `mps_train.py`: Simplified MPS training demo

## How It Works

The system works by:

1. **Encoding**: Converting input images to StyleGAN3's W+ latent space using the HVAE encoder
2. **Compression**: Quantizing the W+ vectors to reduce storage size
3. **Decompression**: Using StyleGAN3's generator to reconstruct the image from the W+ vectors

The HVAE encoder is trained to:
- Minimize reconstruction error between input and output images
- Match the distribution of W+ vectors expected by StyleGAN3
- Extract features hierarchically at multiple scales

## Advanced Configuration

### Compression Parameters

You can control compression quality by adjusting:

- `quantization_bits`: Number of bits per latent dimension (higher = better quality, larger files)
- `block_split`: Control how W vectors are distributed across hierarchy levels
- `deterministic`: Use deterministic encoding for consistent results

### Training Parameters

Key training parameters include:

- `kl_weight`: Controls regularization strength (higher = better distribution matching)
- `perceptual_weight`: Controls perceptual loss importance
- `rec_weight`: Controls reconstruction loss importance
- `resolution`: Training resolution (lower = faster training)

## Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

## License

This project is licensed under the MIT License - see the LICENSE file for details.

## Acknowledgements

- [StyleGAN3 by NVIDIA](https://github.com/NVlabs/stylegan3) - The base generative model used for reconstruction
- [LPIPS](https://github.com/richzhang/PerceptualSimilarity) - Perceptual loss metric

## Citation

If you use this code in your research, please cite:

```
@misc{stylegan3hvae,
  author = {StyleGAN3-HVAE Contributors},
  title = {StyleGAN3-HVAE Image Compression},
  year = {2023},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/yubster4525/image_compression_2}}
}
```